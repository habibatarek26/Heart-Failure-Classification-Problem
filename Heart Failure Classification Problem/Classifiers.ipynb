{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T21:14:14.085527900Z",
     "start_time": "2025-03-11T21:14:14.027294400Z"
    }
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from matplotlib.cm import rainbow\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#pip install scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Download the Heart Failure Prediction Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T21:14:14.154847800Z",
     "start_time": "2025-03-11T21:14:14.091507400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  MaxHR  \\\n0   40   M           ATA        140          289          0     Normal    172   \n1   49   F           NAP        160          180          0     Normal    156   \n2   37   M           ATA        130          283          0         ST     98   \n3   48   F           ASY        138          214          0     Normal    108   \n4   54   M           NAP        150          195          0     Normal    122   \n\n  ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n0              N      0.0       Up             0  \n1              N      1.0     Flat             1  \n2              N      0.0       Up             0  \n3              Y      1.5     Flat             1  \n4              N      0.0       Up             0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>ChestPainType</th>\n      <th>RestingBP</th>\n      <th>Cholesterol</th>\n      <th>FastingBS</th>\n      <th>RestingECG</th>\n      <th>MaxHR</th>\n      <th>ExerciseAngina</th>\n      <th>Oldpeak</th>\n      <th>ST_Slope</th>\n      <th>HeartDisease</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>40</td>\n      <td>M</td>\n      <td>ATA</td>\n      <td>140</td>\n      <td>289</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>172</td>\n      <td>N</td>\n      <td>0.0</td>\n      <td>Up</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>49</td>\n      <td>F</td>\n      <td>NAP</td>\n      <td>160</td>\n      <td>180</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>156</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>Flat</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>37</td>\n      <td>M</td>\n      <td>ATA</td>\n      <td>130</td>\n      <td>283</td>\n      <td>0</td>\n      <td>ST</td>\n      <td>98</td>\n      <td>N</td>\n      <td>0.0</td>\n      <td>Up</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>48</td>\n      <td>F</td>\n      <td>ASY</td>\n      <td>138</td>\n      <td>214</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>108</td>\n      <td>Y</td>\n      <td>1.5</td>\n      <td>Flat</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>54</td>\n      <td>M</td>\n      <td>NAP</td>\n      <td>150</td>\n      <td>195</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>122</td>\n      <td>N</td>\n      <td>0.0</td>\n      <td>Up</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_csv(\"C:\\\\Users\\\\antoi\\\\.cache\\\\kagglehub\\\\datasets\\\\fedesoriano\\\\heart-failure-prediction\\\\versions\\\\1\\heart.csv\")\n",
    "dataset.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T21:14:14.158013800Z",
     "start_time": "2025-03-11T21:14:14.126114400Z"
    }
   },
   "outputs": [],
   "source": [
    "#Setting a random seed ensures that any random processes produce the same results each time the code is run.\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T21:14:14.299171900Z",
     "start_time": "2025-03-11T21:14:14.142442500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "          Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  \\\n0    0.244898   M           ATA       0.70     0.479270        0.0     Normal   \n1    0.428571   F           NAP       0.80     0.298507        0.0     Normal   \n2    0.183673   M           ATA       0.65     0.469320        0.0         ST   \n3    0.408163   F           ASY       0.69     0.354892        0.0     Normal   \n4    0.530612   M           NAP       0.75     0.323383        0.0     Normal   \n..        ...  ..           ...        ...          ...        ...        ...   \n913  0.346939   M            TA       0.55     0.437811        0.0     Normal   \n914  0.816327   M           ASY       0.72     0.320066        1.0     Normal   \n915  0.591837   M           ASY       0.65     0.217247        0.0     Normal   \n916  0.591837   F           ATA       0.65     0.391376        0.0        LVH   \n917  0.204082   M           NAP       0.69     0.290216        0.0     Normal   \n\n        MaxHR ExerciseAngina   Oldpeak ST_Slope  \n0    0.788732              N  0.295455       Up  \n1    0.676056              N  0.409091     Flat  \n2    0.267606              N  0.295455       Up  \n3    0.338028              Y  0.465909     Flat  \n4    0.436620              N  0.295455       Up  \n..        ...            ...       ...      ...  \n913  0.507042              N  0.431818     Flat  \n914  0.570423              N  0.681818     Flat  \n915  0.387324              Y  0.431818     Flat  \n916  0.802817              N  0.295455     Flat  \n917  0.795775              N  0.295455       Up  \n\n[918 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>ChestPainType</th>\n      <th>RestingBP</th>\n      <th>Cholesterol</th>\n      <th>FastingBS</th>\n      <th>RestingECG</th>\n      <th>MaxHR</th>\n      <th>ExerciseAngina</th>\n      <th>Oldpeak</th>\n      <th>ST_Slope</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.244898</td>\n      <td>M</td>\n      <td>ATA</td>\n      <td>0.70</td>\n      <td>0.479270</td>\n      <td>0.0</td>\n      <td>Normal</td>\n      <td>0.788732</td>\n      <td>N</td>\n      <td>0.295455</td>\n      <td>Up</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.428571</td>\n      <td>F</td>\n      <td>NAP</td>\n      <td>0.80</td>\n      <td>0.298507</td>\n      <td>0.0</td>\n      <td>Normal</td>\n      <td>0.676056</td>\n      <td>N</td>\n      <td>0.409091</td>\n      <td>Flat</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.183673</td>\n      <td>M</td>\n      <td>ATA</td>\n      <td>0.65</td>\n      <td>0.469320</td>\n      <td>0.0</td>\n      <td>ST</td>\n      <td>0.267606</td>\n      <td>N</td>\n      <td>0.295455</td>\n      <td>Up</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.408163</td>\n      <td>F</td>\n      <td>ASY</td>\n      <td>0.69</td>\n      <td>0.354892</td>\n      <td>0.0</td>\n      <td>Normal</td>\n      <td>0.338028</td>\n      <td>Y</td>\n      <td>0.465909</td>\n      <td>Flat</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.530612</td>\n      <td>M</td>\n      <td>NAP</td>\n      <td>0.75</td>\n      <td>0.323383</td>\n      <td>0.0</td>\n      <td>Normal</td>\n      <td>0.436620</td>\n      <td>N</td>\n      <td>0.295455</td>\n      <td>Up</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>913</th>\n      <td>0.346939</td>\n      <td>M</td>\n      <td>TA</td>\n      <td>0.55</td>\n      <td>0.437811</td>\n      <td>0.0</td>\n      <td>Normal</td>\n      <td>0.507042</td>\n      <td>N</td>\n      <td>0.431818</td>\n      <td>Flat</td>\n    </tr>\n    <tr>\n      <th>914</th>\n      <td>0.816327</td>\n      <td>M</td>\n      <td>ASY</td>\n      <td>0.72</td>\n      <td>0.320066</td>\n      <td>1.0</td>\n      <td>Normal</td>\n      <td>0.570423</td>\n      <td>N</td>\n      <td>0.681818</td>\n      <td>Flat</td>\n    </tr>\n    <tr>\n      <th>915</th>\n      <td>0.591837</td>\n      <td>M</td>\n      <td>ASY</td>\n      <td>0.65</td>\n      <td>0.217247</td>\n      <td>0.0</td>\n      <td>Normal</td>\n      <td>0.387324</td>\n      <td>Y</td>\n      <td>0.431818</td>\n      <td>Flat</td>\n    </tr>\n    <tr>\n      <th>916</th>\n      <td>0.591837</td>\n      <td>F</td>\n      <td>ATA</td>\n      <td>0.65</td>\n      <td>0.391376</td>\n      <td>0.0</td>\n      <td>LVH</td>\n      <td>0.802817</td>\n      <td>N</td>\n      <td>0.295455</td>\n      <td>Flat</td>\n    </tr>\n    <tr>\n      <th>917</th>\n      <td>0.204082</td>\n      <td>M</td>\n      <td>NAP</td>\n      <td>0.69</td>\n      <td>0.290216</td>\n      <td>0.0</td>\n      <td>Normal</td>\n      <td>0.795775</td>\n      <td>N</td>\n      <td>0.295455</td>\n      <td>Up</td>\n    </tr>\n  </tbody>\n</table>\n<p>918 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset.drop(columns=\"HeartDisease\")  # All columns except the target\n",
    "y = dataset[\"HeartDisease\"]               # Target column\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()  \n",
    "\n",
    "# Normalize only numeric columns\n",
    "for col in X.columns:\n",
    "    if pd.api.types.is_numeric_dtype(X[col]):\n",
    "        X[col] = scaler.fit_transform(X[[col]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T21:14:14.346617800Z",
     "start_time": "2025-03-11T21:14:14.195732600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Age  RestingBP  Cholesterol  FastingBS     MaxHR   Oldpeak  Sex_M  \\\n",
      "0  0.244898       0.70     0.479270        0.0  0.788732  0.295455      1   \n",
      "1  0.428571       0.80     0.298507        0.0  0.676056  0.409091      0   \n",
      "2  0.183673       0.65     0.469320        0.0  0.267606  0.295455      1   \n",
      "3  0.408163       0.69     0.354892        0.0  0.338028  0.465909      0   \n",
      "4  0.530612       0.75     0.323383        0.0  0.436620  0.295455      1   \n",
      "\n",
      "   ChestPainType_ATA  ChestPainType_NAP  ChestPainType_TA  RestingECG_Normal  \\\n",
      "0                  1                  0                 0                  1   \n",
      "1                  0                  1                 0                  1   \n",
      "2                  1                  0                 0                  0   \n",
      "3                  0                  0                 0                  1   \n",
      "4                  0                  1                 0                  1   \n",
      "\n",
      "   RestingECG_ST  ExerciseAngina_Y  ST_Slope_Flat  ST_Slope_Up  \n",
      "0              0                 0              0            1  \n",
      "1              0                 0              1            0  \n",
      "2              1                 0              0            1  \n",
      "3              0                 1              1            0  \n",
      "4              0                 0              0            1  \n"
     ]
    }
   ],
   "source": [
    "#categorical features encoding\n",
    "cat_cols = X.select_dtypes(include='object').columns\n",
    "X = pd.get_dummies(X, columns=cat_cols, drop_first=True)\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Validation/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T21:14:14.356201600Z",
     "start_time": "2025-03-11T21:14:14.235698900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    102\n",
      "0     82\n",
      "Name: HeartDisease, dtype: int64\n",
      "1    51\n",
      "0    41\n",
      "Name: HeartDisease, dtype: int64\n",
      "1    355\n",
      "0    287\n",
      "Name: HeartDisease, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test_val, y_train, y_test_val = train_test_split(\n",
    "    X, y, \n",
    "    random_state=42,   # For reproducibility ------> no need for shuffling\n",
    "    test_size=0.3,     # 30% for testing and validation, 70% for training\n",
    "     stratify=y\n",
    ")\n",
    "\n",
    "X_test, X_val, y_test, y_val = train_test_split(\n",
    "    X_test_val, y_test_val, \n",
    "    random_state=42,   # For reproducibility ------> no need for shuffling\n",
    "    test_size=1/3,     # 20% for testing, 10% for validation of the whole dataset\n",
    "     stratify=y_test_val\n",
    ")\n",
    "\n",
    "#ratio between number of zeros and ones are the same for all sets\n",
    "print(y_test.value_counts())\n",
    "print(y_val.value_counts())\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bagging Ensemble"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datasets = 10, Training Accuracy = 0.9330218068535826\n",
      "Number of datasets = 10, Validation Accuracy = 0.8913043478260869\n",
      "\n",
      "\n",
      "Number of datasets = 15, Training Accuracy = 0.9299065420560748\n",
      "Number of datasets = 15, Validation Accuracy = 0.8586956521739131\n",
      "\n",
      "\n",
      "Number of datasets = 20, Training Accuracy = 0.9361370716510904\n",
      "Number of datasets = 20, Validation Accuracy = 0.8478260869565217\n",
      "\n",
      "\n",
      "Number of datasets = 25, Training Accuracy = 0.9283489096573209\n",
      "Number of datasets = 25, Validation Accuracy = 0.8695652173913043\n",
      "\n",
      "Number of datasets = 30, Training Accuracy = 0.9345794392523364\n",
      "Number of datasets = 30, Validation Accuracy = 0.8586956521739131\n",
      "\n",
      "Number of datasets = 35, Training Accuracy = 0.9376947040498442\n",
      "Number of datasets = 35, Validation Accuracy = 0.8695652173913043\n",
      "\n",
      "Number of datasets = 100, Training Accuracy = 0.9392523364485982\n",
      "Number of datasets = 100, Validation Accuracy = 0.8586956521739131\n",
      "\n",
      "\n",
      "\n",
      "Best n_datasets: 10 with Validation Accuracy: 0.8913043478260869\n",
      "\n",
      "Test accuracy with best n_datasets 10 =  0.8532608695652174\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils import resample\n",
    "\n",
    "#Create bootstrap samples randomly\n",
    "def create_samples(X, y, num_of_resamples):\n",
    "    bootstrap_samples = []\n",
    "    for i in range(num_of_resamples):\n",
    "        resampled_X, resampled_y = resample(X, y, replace = True) \n",
    "        bootstrap_samples.append((resampled_X, resampled_y))\n",
    "\n",
    "\n",
    "    #print(\"-\" * 40)  # Separator for readability       \n",
    "    return bootstrap_samples\n",
    "\n",
    "#obtain decision tree for each bootstrap\n",
    "def train_models(bootstrap_samples):\n",
    "    base_learners = []\n",
    "    for resampled_X, resampled_y in bootstrap_samples:\n",
    "        decision_tree = DecisionTreeClassifier(max_depth=5)    # we need to replace by our implementation\n",
    "        decision_tree.fit(resampled_X, resampled_y)\n",
    "        base_learners.append(decision_tree)\n",
    "        \n",
    "    return base_learners\n",
    "\n",
    "# Calculate majority vote for predictions\n",
    "def majority_predictions(base_learners, X):\n",
    "    # Each col represents the predictions of a certain sample and each row represents a certain decision tree from base_learners\n",
    "    all_predictions = np.array([tree.predict(X) for tree in base_learners]) \n",
    "    final_prediction = np.apply_along_axis(lambda y: np.bincount(y).argmax(), axis=0, arr=all_predictions)\n",
    "     \n",
    "    return final_prediction\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "def bagging_ensemble(X, y, num_of_datasets, X_test_or_val):\n",
    "    bootstrap_samples = create_samples(X, y, num_of_datasets)\n",
    "    base_learners = train_models(bootstrap_samples)\n",
    "    predicted_y = majority_predictions(base_learners, X_test_or_val)\n",
    "    \n",
    "    return predicted_y\n",
    "\n",
    "\n",
    "num_of_datasets = [10, 15, 20, 25, 30, 35, 100]\n",
    "highest_accuracy = 0\n",
    "best_n_dataset = None\n",
    "best_base_learners = []\n",
    "# Evaluate accuracy for different hyperparameter n using validation set\n",
    "for n in num_of_datasets:\n",
    "    \n",
    "    bootstrap_samples = create_samples(X_train, y_train, n)\n",
    "    base_learners = train_models(bootstrap_samples)\n",
    "    predicted_y_training = majority_predictions(base_learners, X_train)\n",
    "    #predicted_y_training = bagging_ensemble(X_train, y_train, n, X_train)\n",
    "    training_accuracy = accuracy_score(y_train, predicted_y_training)\n",
    "    print(f\"Number of datasets = {n}, Training Accuracy = {training_accuracy}\")\n",
    "    \n",
    "    #predicted_y_val = bagging_ensemble(X_train, y_train, n, X_val)\n",
    "    predicted_y_val = majority_predictions(base_learners, X_val)\n",
    "    val_accuracy = accuracy_score(y_val, predicted_y_val)\n",
    "    print(f\"Number of datasets = {n}, Validation Accuracy = {val_accuracy}\")\n",
    "    \n",
    "    \n",
    "    print(\"\\n\")\n",
    "    if val_accuracy > highest_accuracy:\n",
    "        highest_accuracy = val_accuracy\n",
    "        best_n_dataset = n\n",
    "        best_base_learners = base_learners\n",
    "        \n",
    "        \n",
    "print(f\"\\nBest n_datasets: {best_n_dataset} with Validation Accuracy: {highest_accuracy}\")  \n",
    "\n",
    "# Test the model\n",
    "#predicted_y_test = bagging_ensemble(X_train, y_train, best_n_dataset, X_test)\n",
    "predicted_y_test = majority_predictions(best_base_learners, X_test)\n",
    "accuracy = accuracy_score(y_test, predicted_y_test)\n",
    "print(f\"\\nTest accuracy with best n_datasets {best_n_dataset} =  {accuracy}\")  \n",
    "\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T21:14:16.245196800Z",
     "start_time": "2025-03-11T21:14:14.365473Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
